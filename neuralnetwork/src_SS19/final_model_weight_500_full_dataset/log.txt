6745072/6745072 [==============================] - 329s 49us/step - loss: 8.5611 - acc: 0.9388 - val_loss: 1.2147 - val_acc: 0.9089

Epoch 00001: val_loss improved from inf to 1.21474, saving model to M:\dataset2018\model.h5
Epoch 2/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.1759 - acc: 0.9652 - val_loss: 0.4163 - val_acc: 0.9640

Epoch 00002: val_loss improved from 1.21474 to 0.41629, saving model to M:\dataset2018\model.h5
Epoch 3/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.1484 - acc: 0.9676 - val_loss: 0.4991 - val_acc: 0.9553

Epoch 00003: val_loss did not improve from 0.41629
Epoch 4/850
6745072/6745072 [==============================] - 330s 49us/step - loss: 0.1354 - acc: 0.9695 - val_loss: 0.4419 - val_acc: 0.9441

Epoch 00004: val_loss did not improve from 0.41629
Epoch 5/850
6745072/6745072 [==============================] - 327s 48us/step - loss: 0.1304 - acc: 0.9743 - val_loss: 0.0324 - val_acc: 0.9885

Epoch 00005: val_loss improved from 0.41629 to 0.03242, saving model to M:\dataset2018\model.h5
Epoch 6/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.1111 - acc: 0.9772 - val_loss: 0.0975 - val_acc: 0.9626

Epoch 00006: val_loss did not improve from 0.03242
Epoch 7/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0842 - acc: 0.9820 - val_loss: 0.4688 - val_acc: 0.9642

Epoch 00007: val_loss did not improve from 0.03242
Epoch 8/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0850 - acc: 0.9825 - val_loss: 1.0447 - val_acc: 0.9091

Epoch 00008: val_loss did not improve from 0.03242
Epoch 9/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0795 - acc: 0.9832 - val_loss: 0.1939 - val_acc: 0.9677

Epoch 00009: val_loss did not improve from 0.03242
Epoch 10/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0677 - acc: 0.9849 - val_loss: 0.1335 - val_acc: 0.9741

Epoch 00010: val_loss did not improve from 0.03242
Epoch 11/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0980 - acc: 0.9833 - val_loss: 0.5374 - val_acc: 0.9642

Epoch 00011: val_loss did not improve from 0.03242
Epoch 12/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0642 - acc: 0.9857 - val_loss: 0.0223 - val_acc: 0.9941

Epoch 00012: val_loss improved from 0.03242 to 0.02226, saving model to M:\dataset2018\model.h5
Epoch 13/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0644 - acc: 0.9864 - val_loss: 0.0698 - val_acc: 0.9690

Epoch 00013: val_loss did not improve from 0.02226
Epoch 14/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0603 - acc: 0.9880 - val_loss: 0.0321 - val_acc: 0.9840

Epoch 00014: val_loss did not improve from 0.02226
Epoch 15/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0599 - acc: 0.9881 - val_loss: 0.1855 - val_acc: 0.9711

Epoch 00015: val_loss did not improve from 0.02226
Epoch 16/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0596 - acc: 0.9879 - val_loss: 0.2060 - val_acc: 0.9523

Epoch 00016: val_loss did not improve from 0.02226
Epoch 17/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0665 - acc: 0.9868 - val_loss: 0.5332 - val_acc: 0.9619

Epoch 00017: val_loss did not improve from 0.02226
Epoch 18/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0601 - acc: 0.9879 - val_loss: 0.4242 - val_acc: 0.9670

Epoch 00018: val_loss did not improve from 0.02226
Epoch 19/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0540 - acc: 0.9893 - val_loss: 0.3359 - val_acc: 0.9488

Epoch 00019: val_loss did not improve from 0.02226
Epoch 20/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0512 - acc: 0.9900 - val_loss: 0.1813 - val_acc: 0.9648

Epoch 00020: val_loss did not improve from 0.02226
Epoch 21/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0534 - acc: 0.9898 - val_loss: 0.3812 - val_acc: 0.9675

Epoch 00021: val_loss did not improve from 0.02226
Epoch 22/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0512 - acc: 0.9900 - val_loss: 0.3481 - val_acc: 0.9649

Epoch 00022: val_loss did not improve from 0.02226
Epoch 23/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0505 - acc: 0.9904 - val_loss: 0.3875 - val_acc: 0.9647

Epoch 00023: val_loss did not improve from 0.02226
Epoch 24/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0469 - acc: 0.9905 - val_loss: 0.3352 - val_acc: 0.9681

Epoch 00024: val_loss did not improve from 0.02226
Epoch 25/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0507 - acc: 0.9908 - val_loss: 0.0584 - val_acc: 0.9721

Epoch 00025: val_loss did not improve from 0.02226
Epoch 26/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0479 - acc: 0.9907 - val_loss: 0.1465 - val_acc: 0.9667

Epoch 00026: val_loss did not improve from 0.02226
Epoch 27/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0480 - acc: 0.9908 - val_loss: 0.0199 - val_acc: 0.9950

Epoch 00027: val_loss improved from 0.02226 to 0.01991, saving model to M:\dataset2018\model.h5
Epoch 28/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0699 - acc: 0.9902 - val_loss: 0.0373 - val_acc: 0.9920

Epoch 00028: val_loss did not improve from 0.01991
Epoch 29/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0502 - acc: 0.9912 - val_loss: 0.3571 - val_acc: 0.9672

Epoch 00029: val_loss did not improve from 0.01991
Epoch 30/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0447 - acc: 0.9917 - val_loss: 0.4207 - val_acc: 0.9637

Epoch 00030: val_loss did not improve from 0.01991
Epoch 31/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0465 - acc: 0.9916 - val_loss: 0.1590 - val_acc: 0.9788

Epoch 00031: val_loss did not improve from 0.01991
Epoch 32/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0438 - acc: 0.9923 - val_loss: 0.0945 - val_acc: 0.9774

Epoch 00032: val_loss did not improve from 0.01991
Epoch 33/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0468 - acc: 0.9916 - val_loss: 0.1662 - val_acc: 0.9737

Epoch 00033: val_loss did not improve from 0.01991
Epoch 34/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0423 - acc: 0.9924 - val_loss: 0.2682 - val_acc: 0.9681

Epoch 00034: val_loss did not improve from 0.01991
Epoch 35/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0422 - acc: 0.9924 - val_loss: 0.2417 - val_acc: 0.9689

Epoch 00035: val_loss did not improve from 0.01991
Epoch 36/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0423 - acc: 0.9928 - val_loss: 0.0296 - val_acc: 0.9852

Epoch 00036: val_loss did not improve from 0.01991
Epoch 37/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0400 - acc: 0.9923 - val_loss: 0.1754 - val_acc: 0.9702

Epoch 00037: val_loss did not improve from 0.01991
Epoch 38/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0402 - acc: 0.9931 - val_loss: 0.3348 - val_acc: 0.9336

Epoch 00038: val_loss did not improve from 0.01991
Epoch 39/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0421 - acc: 0.9926 - val_loss: 0.3369 - val_acc: 0.9650

Epoch 00039: val_loss did not improve from 0.01991
Epoch 40/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0457 - acc: 0.9925 - val_loss: 0.1426 - val_acc: 0.9731

Epoch 00040: val_loss did not improve from 0.01991
Epoch 41/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0392 - acc: 0.9929 - val_loss: 0.0594 - val_acc: 0.9810

Epoch 00041: val_loss did not improve from 0.01991
Epoch 42/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0363 - acc: 0.9934 - val_loss: 0.3588 - val_acc: 0.9679

Epoch 00042: val_loss did not improve from 0.01991
Epoch 43/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0344 - acc: 0.9938 - val_loss: 0.1248 - val_acc: 0.9851

Epoch 00043: val_loss did not improve from 0.01991
Epoch 44/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0355 - acc: 0.9936 - val_loss: 0.2336 - val_acc: 0.9673

Epoch 00044: val_loss did not improve from 0.01991
Epoch 45/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0370 - acc: 0.9932 - val_loss: 0.0852 - val_acc: 0.9824

Epoch 00045: val_loss did not improve from 0.01991
Epoch 46/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0384 - acc: 0.9934 - val_loss: 0.1396 - val_acc: 0.9814

Epoch 00046: val_loss did not improve from 0.01991
Epoch 47/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0338 - acc: 0.9939 - val_loss: 0.0370 - val_acc: 0.9844

Epoch 00047: val_loss did not improve from 0.01991
Epoch 48/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0381 - acc: 0.9928 - val_loss: 0.3963 - val_acc: 0.9680

Epoch 00048: val_loss did not improve from 0.01991
Epoch 49/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0380 - acc: 0.9936 - val_loss: 0.3610 - val_acc: 0.9701

Epoch 00049: val_loss did not improve from 0.01991
Epoch 50/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0315 - acc: 0.9944 - val_loss: 0.1656 - val_acc: 0.9735

Epoch 00050: val_loss did not improve from 0.01991
Epoch 51/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0320 - acc: 0.9943 - val_loss: 0.1218 - val_acc: 0.9767

Epoch 00051: val_loss did not improve from 0.01991
Epoch 52/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0385 - acc: 0.9929 - val_loss: 0.3916 - val_acc: 0.9645

Epoch 00052: val_loss did not improve from 0.01991
Epoch 53/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0379 - acc: 0.9938 - val_loss: 0.0478 - val_acc: 0.9899

Epoch 00053: val_loss did not improve from 0.01991
Epoch 54/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0389 - acc: 0.9931 - val_loss: 0.1268 - val_acc: 0.9828

Epoch 00054: val_loss did not improve from 0.01991
Epoch 55/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0434 - acc: 0.9929 - val_loss: 0.1523 - val_acc: 0.9737

Epoch 00055: val_loss did not improve from 0.01991
Epoch 56/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0350 - acc: 0.9938 - val_loss: 0.3322 - val_acc: 0.9697

Epoch 00056: val_loss did not improve from 0.01991
Epoch 57/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0338 - acc: 0.9939 - val_loss: 0.1685 - val_acc: 0.9686

Epoch 00057: val_loss did not improve from 0.01991
Epoch 58/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0353 - acc: 0.9941 - val_loss: 0.0188 - val_acc: 0.9889

Epoch 00058: val_loss improved from 0.01991 to 0.01885, saving model to M:\dataset2018\model.h5
Epoch 59/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0374 - acc: 0.9937 - val_loss: 0.1832 - val_acc: 0.9710

Epoch 00059: val_loss did not improve from 0.01885
Epoch 60/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0349 - acc: 0.9941 - val_loss: 0.0265 - val_acc: 0.9956

Epoch 00060: val_loss did not improve from 0.01885
Epoch 61/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0395 - acc: 0.9936 - val_loss: 0.0668 - val_acc: 0.9886

Epoch 00061: val_loss did not improve from 0.01885
Epoch 62/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0349 - acc: 0.9938 - val_loss: 0.1756 - val_acc: 0.9724

Epoch 00062: val_loss did not improve from 0.01885
Epoch 63/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0343 - acc: 0.9944 - val_loss: 0.0275 - val_acc: 0.9854

Epoch 00063: val_loss did not improve from 0.01885
Epoch 64/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0310 - acc: 0.9945 - val_loss: 0.0693 - val_acc: 0.9799

Epoch 00064: val_loss did not improve from 0.01885
Epoch 65/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0301 - acc: 0.9943 - val_loss: 0.0222 - val_acc: 0.9858

Epoch 00065: val_loss did not improve from 0.01885
Epoch 66/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0323 - acc: 0.9943 - val_loss: 0.1718 - val_acc: 0.9733

Epoch 00066: val_loss did not improve from 0.01885
Epoch 67/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0310 - acc: 0.9941 - val_loss: 0.0370 - val_acc: 0.9939

Epoch 00067: val_loss did not improve from 0.01885
Epoch 68/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0312 - acc: 0.9945 - val_loss: 0.0138 - val_acc: 0.9892

Epoch 00068: val_loss improved from 0.01885 to 0.01379, saving model to M:\dataset2018\model.h5
Epoch 69/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0338 - acc: 0.9944 - val_loss: 0.3706 - val_acc: 0.9682

Epoch 00069: val_loss did not improve from 0.01379
Epoch 70/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0323 - acc: 0.9945 - val_loss: 0.0432 - val_acc: 0.9921

Epoch 00070: val_loss did not improve from 0.01379
Epoch 71/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0332 - acc: 0.9939 - val_loss: 0.1065 - val_acc: 0.9815

Epoch 00071: val_loss did not improve from 0.01379
Epoch 72/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0319 - acc: 0.9948 - val_loss: 0.0712 - val_acc: 0.9885

Epoch 00072: val_loss did not improve from 0.01379
Epoch 73/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0315 - acc: 0.9941 - val_loss: 0.0204 - val_acc: 0.9954

Epoch 00073: val_loss did not improve from 0.01379
Epoch 74/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0356 - acc: 0.9944 - val_loss: 0.0190 - val_acc: 0.9951

Epoch 00074: val_loss did not improve from 0.01379
Epoch 75/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0325 - acc: 0.9948 - val_loss: 0.0127 - val_acc: 0.9982

Epoch 00075: val_loss improved from 0.01379 to 0.01266, saving model to M:\dataset2018\model.h5
Epoch 76/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0382 - acc: 0.9942 - val_loss: 0.0227 - val_acc: 0.9953

Epoch 00076: val_loss did not improve from 0.01266
Epoch 77/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0293 - acc: 0.9945 - val_loss: 0.0128 - val_acc: 0.9983

Epoch 00077: val_loss did not improve from 0.01266
Epoch 78/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0323 - acc: 0.9946 - val_loss: 0.0700 - val_acc: 0.9886

Epoch 00078: val_loss did not improve from 0.01266
Epoch 79/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0308 - acc: 0.9945 - val_loss: 0.0646 - val_acc: 0.9882

Epoch 00079: val_loss did not improve from 0.01266
Epoch 80/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0289 - acc: 0.9950 - val_loss: 0.0813 - val_acc: 0.9770

Epoch 00080: val_loss did not improve from 0.01266
Epoch 81/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0299 - acc: 0.9949 - val_loss: 0.0328 - val_acc: 0.9939

Epoch 00081: val_loss did not improve from 0.01266
Epoch 82/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0311 - acc: 0.9945 - val_loss: 0.0617 - val_acc: 0.9684

Epoch 00082: val_loss did not improve from 0.01266
Epoch 83/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0299 - acc: 0.9949 - val_loss: 0.0415 - val_acc: 0.9822

Epoch 00083: val_loss did not improve from 0.01266
Epoch 84/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0305 - acc: 0.9943 - val_loss: 0.0269 - val_acc: 0.9936

Epoch 00084: val_loss did not improve from 0.01266
Epoch 85/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0302 - acc: 0.9944 - val_loss: 0.0252 - val_acc: 0.9949

Epoch 00085: val_loss did not improve from 0.01266
Epoch 86/850
6745072/6745072 [==============================] - 322s 48us/step - loss: 0.0303 - acc: 0.9944 - val_loss: 0.3243 - val_acc: 0.9675

Epoch 00086: val_loss did not improve from 0.01266
Epoch 87/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0337 - acc: 0.9937 - val_loss: 0.0437 - val_acc: 0.9831

Epoch 00087: val_loss did not improve from 0.01266
Epoch 88/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0329 - acc: 0.9946 - val_loss: 0.4098 - val_acc: 0.9669

Epoch 00088: val_loss did not improve from 0.01266
Epoch 89/850
6745072/6745072 [==============================] - 327s 48us/step - loss: 0.0300 - acc: 0.9943 - val_loss: 0.0909 - val_acc: 0.9792

Epoch 00089: val_loss did not improve from 0.01266
Epoch 90/850
6745072/6745072 [==============================] - 328s 49us/step - loss: 0.0291 - acc: 0.9947 - val_loss: 0.0432 - val_acc: 0.9901

Epoch 00090: val_loss did not improve from 0.01266
Epoch 91/850
6745072/6745072 [==============================] - 333s 49us/step - loss: 0.0299 - acc: 0.9948 - val_loss: 0.1734 - val_acc: 0.9681

Epoch 00091: val_loss did not improve from 0.01266
Epoch 92/850
6745072/6745072 [==============================] - 335s 50us/step - loss: 0.0279 - acc: 0.9947 - val_loss: 0.0129 - val_acc: 0.9979

Epoch 00092: val_loss did not improve from 0.01266
Epoch 93/850
6745072/6745072 [==============================] - 334s 49us/step - loss: 0.0295 - acc: 0.9945 - val_loss: 0.0501 - val_acc: 0.9927

Epoch 00093: val_loss did not improve from 0.01266
Epoch 94/850
6745072/6745072 [==============================] - 339s 50us/step - loss: 0.0272 - acc: 0.9952 - val_loss: 0.0137 - val_acc: 0.9977

Epoch 00094: val_loss did not improve from 0.01266
Epoch 95/850
6745072/6745072 [==============================] - 336s 50us/step - loss: 0.0295 - acc: 0.9950 - val_loss: 0.1182 - val_acc: 0.9713

Epoch 00095: val_loss did not improve from 0.01266
Epoch 96/850
6745072/6745072 [==============================] - 383s 57us/step - loss: 0.0318 - acc: 0.9950 - val_loss: 0.0496 - val_acc: 0.9728

Epoch 00096: val_loss did not improve from 0.01266
Epoch 97/850
6745072/6745072 [==============================] - 403s 60us/step - loss: 0.0292 - acc: 0.9946 - val_loss: 0.0985 - val_acc: 0.9886

Epoch 00097: val_loss did not improve from 0.01266
Epoch 98/850
6745072/6745072 [==============================] - 402s 60us/step - loss: 0.0287 - acc: 0.9946 - val_loss: 0.0147 - val_acc: 0.9980

Epoch 00098: val_loss did not improve from 0.01266
Epoch 99/850
6745072/6745072 [==============================] - 394s 58us/step - loss: 0.0346 - acc: 0.9941 - val_loss: 0.1145 - val_acc: 0.9844

Epoch 00099: val_loss did not improve from 0.01266
Epoch 100/850
6745072/6745072 [==============================] - 401s 59us/step - loss: 0.0294 - acc: 0.9949 - val_loss: 0.3652 - val_acc: 0.9684

Epoch 00100: val_loss did not improve from 0.01266
Epoch 101/850
6745072/6745072 [==============================] - 398s 59us/step - loss: 0.0314 - acc: 0.9947 - val_loss: 0.0121 - val_acc: 0.9985

Epoch 00101: val_loss improved from 0.01266 to 0.01208, saving model to M:\dataset2018\model.h5
Epoch 102/850
6745072/6745072 [==============================] - 415s 62us/step - loss: 0.0314 - acc: 0.9946 - val_loss: 0.0139 - val_acc: 0.9980

Epoch 00102: val_loss did not improve from 0.01208
Epoch 103/850
6745072/6745072 [==============================] - 401s 59us/step - loss: 0.0283 - acc: 0.9947 - val_loss: 0.0335 - val_acc: 0.9946

Epoch 00103: val_loss did not improve from 0.01208
Epoch 104/850
6745072/6745072 [==============================] - 396s 59us/step - loss: 0.0304 - acc: 0.9947 - val_loss: 0.0248 - val_acc: 0.9858

Epoch 00104: val_loss did not improve from 0.01208
Epoch 105/850
6745072/6745072 [==============================] - 400s 59us/step - loss: 0.0292 - acc: 0.9948 - val_loss: 0.0277 - val_acc: 0.9977

Epoch 00105: val_loss did not improve from 0.01208
Epoch 106/850
6745072/6745072 [==============================] - 406s 60us/step - loss: 0.0297 - acc: 0.9949 - val_loss: 0.2048 - val_acc: 0.9682

Epoch 00106: val_loss did not improve from 0.01208
Epoch 107/850
6745072/6745072 [==============================] - 337s 50us/step - loss: 0.0285 - acc: 0.9948 - val_loss: 0.0326 - val_acc: 0.9849

Epoch 00107: val_loss did not improve from 0.01208
Epoch 108/850
6745072/6745072 [==============================] - 345s 51us/step - loss: 0.0276 - acc: 0.9949 - val_loss: 0.0423 - val_acc: 0.9835

Epoch 00108: val_loss did not improve from 0.01208
Epoch 109/850
6745072/6745072 [==============================] - 346s 51us/step - loss: 0.0298 - acc: 0.9946 - val_loss: 0.0305 - val_acc: 0.9953

Epoch 00109: val_loss did not improve from 0.01208
Epoch 110/850
6745072/6745072 [==============================] - 354s 52us/step - loss: 0.0278 - acc: 0.9952 - val_loss: 0.0203 - val_acc: 0.9955

Epoch 00110: val_loss did not improve from 0.01208
Epoch 111/850
6745072/6745072 [==============================] - 353s 52us/step - loss: 0.0274 - acc: 0.9954 - val_loss: 0.0191 - val_acc: 0.9954

Epoch 00111: val_loss did not improve from 0.01208
Epoch 112/850
6745072/6745072 [==============================] - 350s 52us/step - loss: 0.0295 - acc: 0.9947 - val_loss: 0.1329 - val_acc: 0.9852

Epoch 00112: val_loss did not improve from 0.01208
Epoch 113/850
6745072/6745072 [==============================] - 370s 55us/step - loss: 0.0285 - acc: 0.9949 - val_loss: 0.0741 - val_acc: 0.9855

Epoch 00113: val_loss did not improve from 0.01208
Epoch 114/850
6745072/6745072 [==============================] - 356s 53us/step - loss: 0.0301 - acc: 0.9950 - val_loss: 0.1676 - val_acc: 0.9707

Epoch 00114: val_loss did not improve from 0.01208
Epoch 115/850
6745072/6745072 [==============================] - 377s 56us/step - loss: 0.0289 - acc: 0.9950 - val_loss: 0.0238 - val_acc: 0.9951

Epoch 00115: val_loss did not improve from 0.01208
Epoch 116/850
6745072/6745072 [==============================] - 351s 52us/step - loss: 0.0295 - acc: 0.9945 - val_loss: 0.0206 - val_acc: 0.9865

Epoch 00116: val_loss did not improve from 0.01208
Epoch 117/850
6745072/6745072 [==============================] - 345s 51us/step - loss: 0.0268 - acc: 0.9952 - val_loss: 0.0379 - val_acc: 0.9834

Epoch 00117: val_loss did not improve from 0.01208
Epoch 118/850
6745072/6745072 [==============================] - 358s 53us/step - loss: 0.0300 - acc: 0.9949 - val_loss: 0.1999 - val_acc: 0.9744

Epoch 00118: val_loss did not improve from 0.01208
Epoch 119/850
6745072/6745072 [==============================] - 347s 51us/step - loss: 0.0303 - acc: 0.9950 - val_loss: 0.3552 - val_acc: 0.9675

Epoch 00119: val_loss did not improve from 0.01208
Epoch 120/850
6745072/6745072 [==============================] - 330s 49us/step - loss: 0.0291 - acc: 0.9953 - val_loss: 0.4532 - val_acc: 0.9675

Epoch 00120: val_loss did not improve from 0.01208
Epoch 121/850
6745072/6745072 [==============================] - 338s 50us/step - loss: 0.0299 - acc: 0.9951 - val_loss: 0.1781 - val_acc: 0.9747

Epoch 00121: val_loss did not improve from 0.01208
Epoch 122/850
6745072/6745072 [==============================] - 336s 50us/step - loss: 0.0280 - acc: 0.9947 - val_loss: 0.0275 - val_acc: 0.9859

Epoch 00122: val_loss did not improve from 0.01208
Epoch 123/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0292 - acc: 0.9944 - val_loss: 0.1286 - val_acc: 0.9851

Epoch 00123: val_loss did not improve from 0.01208
Epoch 124/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0301 - acc: 0.9947 - val_loss: 0.0252 - val_acc: 0.9856

Epoch 00124: val_loss did not improve from 0.01208
Epoch 125/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0304 - acc: 0.9948 - val_loss: 0.1503 - val_acc: 0.9764

Epoch 00125: val_loss did not improve from 0.01208
Epoch 126/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0299 - acc: 0.9950 - val_loss: 0.0157 - val_acc: 0.9978

Epoch 00126: val_loss did not improve from 0.01208
Epoch 127/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0269 - acc: 0.9950 - val_loss: 0.0144 - val_acc: 0.9890

Epoch 00127: val_loss did not improve from 0.01208
Epoch 128/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0304 - acc: 0.9946 - val_loss: 0.0109 - val_acc: 0.9985

Epoch 00128: val_loss improved from 0.01208 to 0.01090, saving model to M:\dataset2018\model.h5
Epoch 129/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0280 - acc: 0.9950 - val_loss: 0.0798 - val_acc: 0.9732

Epoch 00129: val_loss did not improve from 0.01090
Epoch 130/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0294 - acc: 0.9946 - val_loss: 0.0265 - val_acc: 0.9862

Epoch 00130: val_loss did not improve from 0.01090
Epoch 131/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0308 - acc: 0.9948 - val_loss: 0.0897 - val_acc: 0.9784

Epoch 00131: val_loss did not improve from 0.01090
Epoch 132/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0269 - acc: 0.9949 - val_loss: 0.1289 - val_acc: 0.9773

Epoch 00132: val_loss did not improve from 0.01090
Epoch 133/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0273 - acc: 0.9950 - val_loss: 0.0118 - val_acc: 0.9986

Epoch 00133: val_loss did not improve from 0.01090
Epoch 134/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0270 - acc: 0.9950 - val_loss: 0.0213 - val_acc: 0.9884

Epoch 00134: val_loss did not improve from 0.01090
Epoch 135/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0285 - acc: 0.9946 - val_loss: 0.0674 - val_acc: 0.9822

Epoch 00135: val_loss did not improve from 0.01090
Epoch 136/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0297 - acc: 0.9950 - val_loss: 0.0133 - val_acc: 0.9953

Epoch 00136: val_loss did not improve from 0.01090
Epoch 137/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0302 - acc: 0.9947 - val_loss: 0.0101 - val_acc: 0.9985

Epoch 00137: val_loss improved from 0.01090 to 0.01007, saving model to M:\dataset2018\model.h5
Epoch 138/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0270 - acc: 0.9951 - val_loss: 0.0477 - val_acc: 0.9851

Epoch 00138: val_loss did not improve from 0.01007
Epoch 139/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0287 - acc: 0.9947 - val_loss: 0.0180 - val_acc: 0.9894

Epoch 00139: val_loss did not improve from 0.01007
Epoch 140/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0299 - acc: 0.9948 - val_loss: 0.0179 - val_acc: 0.9958

Epoch 00140: val_loss did not improve from 0.01007
Epoch 141/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0277 - acc: 0.9952 - val_loss: 0.0179 - val_acc: 0.9889

Epoch 00141: val_loss did not improve from 0.01007
Epoch 142/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0274 - acc: 0.9952 - val_loss: 0.0138 - val_acc: 0.9906

Epoch 00142: val_loss did not improve from 0.01007
Epoch 143/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0274 - acc: 0.9954 - val_loss: 0.0304 - val_acc: 0.9936

Epoch 00143: val_loss did not improve from 0.01007
Epoch 144/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0293 - acc: 0.9947 - val_loss: 0.0315 - val_acc: 0.9880

Epoch 00144: val_loss did not improve from 0.01007
Epoch 145/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0274 - acc: 0.9950 - val_loss: 0.0258 - val_acc: 0.9946

Epoch 00145: val_loss did not improve from 0.01007
Epoch 146/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0273 - acc: 0.9952 - val_loss: 0.0120 - val_acc: 0.9984

Epoch 00146: val_loss did not improve from 0.01007
Epoch 147/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0312 - acc: 0.9942 - val_loss: 0.1045 - val_acc: 0.9771

Epoch 00147: val_loss did not improve from 0.01007
Epoch 148/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0292 - acc: 0.9949 - val_loss: 0.2226 - val_acc: 0.9774

Epoch 00148: val_loss did not improve from 0.01007
Epoch 149/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0276 - acc: 0.9949 - val_loss: 0.0690 - val_acc: 0.9815

Epoch 00149: val_loss did not improve from 0.01007
Epoch 150/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0315 - acc: 0.9945 - val_loss: 0.0435 - val_acc: 0.9934

Epoch 00150: val_loss did not improve from 0.01007
Epoch 151/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0270 - acc: 0.9947 - val_loss: 0.1902 - val_acc: 0.9646

Epoch 00151: val_loss did not improve from 0.01007
Epoch 152/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0278 - acc: 0.9948 - val_loss: 0.0561 - val_acc: 0.9922

Epoch 00152: val_loss did not improve from 0.01007
Epoch 153/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0302 - acc: 0.9946 - val_loss: 0.0142 - val_acc: 0.9983

Epoch 00153: val_loss did not improve from 0.01007
Epoch 154/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0303 - acc: 0.9947 - val_loss: 0.5129 - val_acc: 0.9679

Epoch 00154: val_loss did not improve from 0.01007
Epoch 155/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0294 - acc: 0.9951 - val_loss: 0.0135 - val_acc: 0.9977

Epoch 00155: val_loss did not improve from 0.01007
Epoch 156/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0289 - acc: 0.9950 - val_loss: 0.0150 - val_acc: 0.9982

Epoch 00156: val_loss did not improve from 0.01007
Epoch 157/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0275 - acc: 0.9949 - val_loss: 0.0118 - val_acc: 0.9979

Epoch 00157: val_loss did not improve from 0.01007
Epoch 158/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0261 - acc: 0.9953 - val_loss: 0.0324 - val_acc: 0.9945

Epoch 00158: val_loss did not improve from 0.01007
Epoch 159/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0311 - acc: 0.9948 - val_loss: 0.0245 - val_acc: 0.9955

Epoch 00159: val_loss did not improve from 0.01007
Epoch 160/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0324 - acc: 0.9949 - val_loss: 0.0151 - val_acc: 0.9886

Epoch 00160: val_loss did not improve from 0.01007
Epoch 161/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0304 - acc: 0.9947 - val_loss: 0.0296 - val_acc: 0.9854

Epoch 00161: val_loss did not improve from 0.01007
Epoch 162/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0265 - acc: 0.9950 - val_loss: 0.0386 - val_acc: 0.9850

Epoch 00162: val_loss did not improve from 0.01007
Epoch 163/850
6745072/6745072 [==============================] - 325s 48us/step - loss: 0.0286 - acc: 0.9950 - val_loss: 0.1110 - val_acc: 0.9875

Epoch 00163: val_loss did not improve from 0.01007
Epoch 164/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0275 - acc: 0.9950 - val_loss: 0.0127 - val_acc: 0.9985

Epoch 00164: val_loss did not improve from 0.01007
Epoch 165/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0275 - acc: 0.9949 - val_loss: 0.0223 - val_acc: 0.9945

Epoch 00165: val_loss did not improve from 0.01007
Epoch 166/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0275 - acc: 0.9949 - val_loss: 0.0307 - val_acc: 0.9930

Epoch 00166: val_loss did not improve from 0.01007
Epoch 167/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0278 - acc: 0.9949 - val_loss: 0.0198 - val_acc: 0.9958

Epoch 00167: val_loss did not improve from 0.01007
Epoch 168/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0300 - acc: 0.9949 - val_loss: 0.0385 - val_acc: 0.9927

Epoch 00168: val_loss did not improve from 0.01007
Epoch 169/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0324 - acc: 0.9949 - val_loss: 0.0252 - val_acc: 0.9956

Epoch 00169: val_loss did not improve from 0.01007
Epoch 170/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0263 - acc: 0.9953 - val_loss: 0.0155 - val_acc: 0.9982

Epoch 00170: val_loss did not improve from 0.01007
Epoch 171/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0273 - acc: 0.9953 - val_loss: 0.0179 - val_acc: 0.9902

Epoch 00171: val_loss did not improve from 0.01007
Epoch 172/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0271 - acc: 0.9950 - val_loss: 0.0653 - val_acc: 0.9847

Epoch 00172: val_loss did not improve from 0.01007
Epoch 173/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0301 - acc: 0.9947 - val_loss: 0.0475 - val_acc: 0.9925

Epoch 00173: val_loss did not improve from 0.01007
Epoch 174/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0270 - acc: 0.9954 - val_loss: 0.0214 - val_acc: 0.9953

Epoch 00174: val_loss did not improve from 0.01007
Epoch 175/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0281 - acc: 0.9949 - val_loss: 0.0135 - val_acc: 0.9983

Epoch 00175: val_loss did not improve from 0.01007
Epoch 176/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0293 - acc: 0.9950 - val_loss: 0.0264 - val_acc: 0.9932

Epoch 00176: val_loss did not improve from 0.01007
Epoch 177/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0306 - acc: 0.9948 - val_loss: 0.0131 - val_acc: 0.9984

Epoch 00177: val_loss did not improve from 0.01007
Epoch 178/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0278 - acc: 0.9946 - val_loss: 0.0369 - val_acc: 0.9926

Epoch 00178: val_loss did not improve from 0.01007
Epoch 179/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0258 - acc: 0.9952 - val_loss: 0.0152 - val_acc: 0.9895

Epoch 00179: val_loss did not improve from 0.01007
Epoch 180/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0268 - acc: 0.9952 - val_loss: 0.0413 - val_acc: 0.9893

Epoch 00180: val_loss did not improve from 0.01007
Epoch 181/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0286 - acc: 0.9949 - val_loss: 0.3550 - val_acc: 0.9685

Epoch 00181: val_loss did not improve from 0.01007
Epoch 182/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0266 - acc: 0.9952 - val_loss: 0.2901 - val_acc: 0.9687

Epoch 00182: val_loss did not improve from 0.01007
Epoch 183/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0286 - acc: 0.9953 - val_loss: 0.0141 - val_acc: 0.9983

Epoch 00183: val_loss did not improve from 0.01007
Epoch 184/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0278 - acc: 0.9947 - val_loss: 0.0606 - val_acc: 0.9872

Epoch 00184: val_loss did not improve from 0.01007
Epoch 185/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0264 - acc: 0.9953 - val_loss: 0.1097 - val_acc: 0.9779

Epoch 00185: val_loss did not improve from 0.01007
Epoch 186/850
6745072/6745072 [==============================] - 323s 48us/step - loss: 0.0283 - acc: 0.9947 - val_loss: 0.0133 - val_acc: 0.9981

Epoch 00186: val_loss did not improve from 0.01007
Epoch 187/850
6745072/6745072 [==============================] - 324s 48us/step - loss: 0.0282 - acc: 0.9950 - val_loss: 0.1087 - val_acc: 0.9877

Epoch 00187: val_loss did not improve from 0.01007
Epoch 00187: early stopping
2107836/2107836 [==============================] - 20s 10us/step
Test performance:  [0.11068059282236305, 0.9874862180903803]
